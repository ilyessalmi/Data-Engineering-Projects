# Application Web & Pipeline Big Data : Analyse de Feedback

![Docker](https://img.shields.io/badge/Docker-Container-blue?style=for-the-badge&logo=docker) ![Hadoop](https://img.shields.io/badge/Hadoop-HDFS-yellow?style=for-the-badge&logo=apache-hadoop) ![Flask](https://img.shields.io/badge/Python-Flask-green?style=for-the-badge&logo=flask) ![Linux](https://img.shields.io/badge/Linux-Shell-black?style=for-the-badge&logo=linux)

## üìã Pr√©sentation du projet

Ce projet "Capstone" repr√©sente une **int√©gration syst√®me compl√®te**. L'objectif √©tait de construire une application web permettant aux √©tudiants de donner leur avis sur des cours, et de traiter ces donn√©es via un √©cosyst√®me Big Data local.

Ce n'est pas seulement un projet de d√©veloppement, mais un **d√©fi d'architecture syst√®me**. Il a fallu interconnecter des environnements h√©t√©rog√®nes (Web App l√©g√®re vs Infrastructure Hadoop lourde), g√©rer les r√©seaux Docker et orchestrer des flux de donn√©es automatis√©s.


## üõ† Architecture et Flux de Donn√©es

L'architecture repose sur une communication entre un conteneur applicatif et un cluster de donn√©es local.

```mermaid
graph TD
    %% Styles
    classDef web fill:#4b0082,stroke:#fff,stroke-width:2px,color:#fff,rx:5,ry:5;
    classDef data fill:#0078D4,stroke:#fff,stroke-width:2px,color:#fff,rx:5,ry:5;
    classDef storage fill:#ff8c00,stroke:#fff,stroke-width:2px,color:#fff,rx:5,ry:5;
    classDef container fill:#fff,stroke:#333,stroke-width:2px,stroke-dasharray: 5 5,color:#333;

    subgraph Docker_Container ["üê≥ Conteneur Docker (Application)"]
        User((Utilisateur))
        WebApp["Interface Web HTML/JS"]:::web
        Backend["API Flask Python"]:::web
    end

    subgraph BigData_Ecosystem ["üêò √âcosyst√®me Hadoop Local"]
        HDFS["HDFS Stockage Distribu√©"]:::storage
        Hive["Apache Hive SQL"]:::data
        Scala["MapReduce Scala Analysis"]:::data
    end

    User -->|Soumet Feedback| WebApp
    WebApp -->|POST Request - Port 5000| Backend
    Backend -->|√âcriture fichier via WebHDFS - Port 9870| HDFS
    Hive -->|Mapping Table Externe| HDFS
    Scala -->|Job Analyse Sentiment| HDFS
    Backend -.->|Lecture Insights| Hive

    %% Subgraph Styling - Added color:#000 (Black Text)
    style Docker_Container fill:#f9f9f9,stroke:#666,color:#000
    style BigData_Ecosystem fill:#e6f7ff,stroke:#0078D4,color:#000
```


## üíª D√©tails Techniques et Configuration

### 1. Backend Python (Int√©gration HDFS)
Le d√©fi principal √©tait de permettre √† Python d'√©crire dans un syst√®me de fichiers distribu√© (HDFS) sans passer par des commandes syst√®me locales, mais via le r√©seau. J'ai utilis√© le client pywebhdfs pour interagir avec le NameNode.

Extrait : Logique d'√©criture et gestion d'erreurs
```python
# Exemple de logique d'√©criture dans HDFS
from pywebhdfs.webhdfs import PyWebHdfsClient
try:
    # Connexion au NameNode via WebHDFS
    hdfs = PyWebHdfsClient(host='host.docker.internal', port='9870', user_name='hdfs')
    hdfs.append_file('/user/hdfs/feedbacks.csv', data_to_append)
    
    # Message de succ√®s (Flask flash)
    flash("Retour enregistr√© avec succ√®s dans le Data Lake.", "success")
except Exception as e:
    # Gestion critique si HDFS est en Safe Mode ou inaccessible
    print(f"Erreur de connexion HDFS : {str(e)}")
    flash("Erreur serveur de stockage. Veuillez r√©essayer.", "danger")
```
    
### 2. Conteneurisation (Docker)
L'application web est conteneuris√©e pour garantir la portabilit√© et faciliter le d√©ploiement.
Dockerfile utilis√© :
```dockerfile
FROM python:3.12
WORKDIR /app
# Installation des d√©pendances
COPY requirements.txt .
RUN pip install -r requirements.txt
# Copie du code source
COPY . .
# Exposition du port Flask
EXPOSE 5000
# Commande de d√©marrage
CMD ["python", "app.py"]
```

### 3. Pipeline Big Data
* HDFS : Stockage distribu√© des fichiers .csv bruts.
* Apache Hive : Utilisation de Tables Externes pour appliquer un sch√©ma SQL sur les donn√©es brutes de HDFS, permettant des requ√™tes d'analyse rapides.
* Scala (MapReduce) : Utilisation pour des jobs d'analyse de sentiment plus complexes sur le corpus de feedback.


## üîß Troubleshooting et R√©solution de Probl√®mes
En tant qu'administrateur de cette stack, j'ai d√ª r√©soudre plusieurs incidents techniques majeurs durant le projet :

### üî¥ Probl√®me 1 : HDFS en "Safe Mode"
* Sympt√¥me : L'application Python plantait lors de l'√©criture des fichiers. Erreur : NameNode is in safe mode.
* Analyse : HDFS se met en protection s'il manque des DataNodes ou si l'espace disque est critique.
* R√©solution : Analyse des logs Hadoop, puis ex√©cution de la commande d'admin : hdfs dfsadmin -safemode leave.

### üî¥ Probl√®me 2 : Conflits de Ports (Docker vs Localhost)
* Sympt√¥me : Le conteneur Docker n'arrivait pas √† contacter le service Hadoop h√©berg√© sur la machine h√¥te.
* R√©solution : Configuration du r√©seau Docker. Utilisation de host.docker.internal (ou --network host) pour permettre au conteneur de " voir" le port 9870 de la machine h√¥te.

### üî¥ Probl√®me 3 : Versions Java (Hive vs Hadoop)
* Sympt√¥me : Hive refusait de d√©marrer (Stack Traces Java complexes).
* Cause : Incompatibilit√© entre les biblioth√®ques guava de Hadoop et celles de Hive.
* R√©solution : Localisation des JARs conflictuels et remplacement manuel des fichiers .jar pour uniformiser les versions.


## üì∏ Aper√ßu de l'Infrastructure
### 1. Interface Web Utilisateur
Le point d'entr√©e pour les utilisateurs.

![alt text](web-interface.jpg)


### 2. Gestion du Cluster Hadoop
V√©rification des fichiers stock√©s directement dans l'interface HDFS.

![alt text](hadoop-cluster.jpg)


### 3. Ex√©cution des requ√™tes Hive
Traitement des donn√©es via terminal SQL-like.

![alt text](hive-terminal.jpg)


### 4. D√©ploiement Docker
V√©rification du build et du run de l'image.

![alt text](docker-deploy.jpg)


### 5. Test E2E avec Cypress
Mise en place de tests E2E avec Cypress pour valider la stabilit√© de l'application avant d√©ploiement.

![alt text](test-E2E-cypress.jpg)


---


## üöÄ Bilan : Comp√©tences SysAdmin / Cloud
Ce projet a renforc√© mes comp√©tences en :
* Administration Linux/Hadoop : Gestion des services (start-yarn, start-dfs), gestion des permissions utilisateurs HDFS.
* Virtualisation : Cr√©ation et d√©bogage de conteneurs Docker.
* R√©seau Applicatif : Compr√©hension des flux HTTP REST et des connexions RPC Hadoop.
* QA & Testing : Mise en place de tests E2E avec Cypress pour valider la stabilit√© de l'application avant d√©ploiement.
