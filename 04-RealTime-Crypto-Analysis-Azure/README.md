# Analyse Temps RÃ©el du MarchÃ© Crypto (Streaming Azure)

![Azure](https://img.shields.io/badge/Azure-Serverless-0078D4?style=for-the-badge&logo=microsoft-azure) ![Event Hubs](https://img.shields.io/badge/Azure-Event_Hubs-0078D4?style=for-the-badge) ![Stream Analytics](https://img.shields.io/badge/Stream-Analytics-orange?style=for-the-badge) ![Synapse](https://img.shields.io/badge/Azure-Synapse-0078D4?style=for-the-badge)

## ðŸ“‹ RÃ©sumÃ© ExÃ©cutif

Ce projet Capstone final vise Ã  construire une architecture **100% Cloud Native (PaaS)** pour l'analyse en temps rÃ©el des cryptomonnaies (Bitcoin & Ethereum). Contrairement aux traitements par lots (Batch) classiques, ce projet traite les donnÃ©es "au fil de l'eau" (Streaming) pour permettre une rÃ©activitÃ© immÃ©diate.

L'objectif Ã©tait double :
1.  **Architecture Cloud :** Interconnecter des services Azure managÃ©s (Functions, Event Hubs, Stream Analytics) de maniÃ¨re sÃ©curisÃ©e et scalable.
2.  **Data Intelligence :** Calculer des indicateurs financiers (Moyennes mobiles, VolatilitÃ©) en temps rÃ©el et gÃ©nÃ©rer des alertes critiques pour les traders.

## ðŸ›  Architecture Technique (Azure PaaS)

L'architecture repose sur un flux continu de donnÃ©es, orchestrÃ© sans aucun serveur Ã  gÃ©rer (Serverless).

```mermaid
graph TD
    %% Styles
    classDef source fill:#f9f9f9,stroke:#333,stroke-width:2px;
    classDef ingest fill:#0078D4,stroke:#fff,stroke-width:2px,color:#fff;
    classDef process fill:#E66C37,stroke:#fff,stroke-width:2px,color:#fff;
    classDef storage fill:#004C87,stroke:#fff,stroke-width:2px,color:#fff;
    classDef viz fill:#F2C811,stroke:#fff,stroke-width:2px,color:#000;

    subgraph External ["Source de DonnÃ©es"]
        API["API CoinGecko"]:::source
    end

    subgraph Ingestion ["1. Ingestion Serverless"]
        AzFunc["Azure Function (Timer Trigger)"]:::ingest
        EventHub["Azure Event Hubs (Kafka)"]:::ingest
    end

    subgraph Processing ["2. Traitement Temps RÃ©el"]
        Stream["Azure Stream Analytics"]:::process
    end

    subgraph Storage_Analyze ["3. Stockage & Analyse"]
        Synapse["Azure Synapse SQL Pool"]:::storage
        Monitor["Azure Monitor (Alertes)"]:::storage
    end

    subgraph Viz ["4. Restitution"]
        PBI["Power BI Dashboard"]:::viz
    end

    %% Flux
    API -->|JSON Request (5min)| AzFunc
    AzFunc -->|Push Data| EventHub
    EventHub -->|Ingest Stream| Stream
    Stream -->|Calculs FenÃªtrÃ©s (SQL)| Synapse
    Synapse -->|Direct Query| PBI
    Stream -.->|Condition Critique| Monitor

    %% Styling
    style External fill:#fff,stroke:#333,color:#000
    style Ingestion fill:#e6f7ff,stroke:#0078D4,color:#000
    style Processing fill:#fff5e6,stroke:#E66C37,color:#000
    style Storage_Analyze fill:#e6efff,stroke:#004C87,color:#000
    style Viz fill:#fff5f0,stroke:#F2C811,color:#000
```

## ðŸ’» ImplÃ©mentation Data Engineering
### 1. Ingestion Serverless (Python)
J'ai dÃ©veloppÃ© une Azure Function dÃ©clenchÃ©e par un Timer Trigger (toutes les 5 minutes) pour interroger l'API CoinGecko. Le code est conÃ§u pour Ãªtre rÃ©silient aux pannes API.
Voir le code complet : function_app.py
```Python
# Extrait de l'Azure Function
@app.function_name(name="IngestCurrentCryptoData")
@app.schedule(schedule="0 */5 * * * *", ...) 
def ingest_current_crypto_data(myTimer: func.TimerRequest) -> None:
    try:
        url = "https://api.coingecko.com/api/v3/coins/markets?..."
        response = requests.get(url)
        # Envoi direct vers Event Hub via le binding Azure SDK
        event_hub_client.send_batch(batch_data)
        logging.info("DonnÃ©es envoyÃ©es avec succÃ¨s Ã  Event Hub")
    except Exception as e:
        logging.error(f"Erreur critique lors de l'ingestion: {e}")
```

### 2. Traitement de Flux (Stream Analytics SQL)
Le cÅ“ur du traitement n'est pas en Python, mais en SQL Temporel. J'ai configurÃ© un job Stream Analytics pour calculer des agrÃ©gats sur des fenÃªtres de temps glissantes (Tumbling Windows).
RequÃªte de transformation (Calcul de Moyennes et VolatilitÃ©) :
```SQL
SELECT
    System.Timestamp AS event_time,
    id AS coin,
    AVG(current_price) OVER (PARTITION BY id LIMIT DURATION(hour, 1)) AS avg_price_1h,
    -- Calcul de la volatilitÃ© sur fenÃªtre glissante
    STDEV(current_price) OVER (PARTITION BY id LIMIT DURATION(hour, 24)) AS volatility_24h
INTO
    CryptoIndicatorsOutput -- Vers Synapse Analytics
FROM
    crypto_eventhub
WHERE
    type = 'current'
```

## âš™ï¸ Administration Cloud & Gouvernance
Ce projet a nÃ©cessitÃ© une configuration fine des ressources Azure pour assurer la sÃ©curitÃ© et la maÃ®trise des coÃ»ts.

### 1. Configuration Infrastructure (IaC & Portail)
Event Hubs : CrÃ©ation d'un Namespace dÃ©diÃ© avec partitionnement pour parallÃ©liser l'ingestion si le volume augmente.
Synapse Analytics : Provisionnement d'un Pool SQL dÃ©diÃ© (DW) pour stocker l'historique et permettre des requÃªtes analytiques complexes.

### 2. Monitoring & Alerting (Azure Monitor)
En tant qu'Admin, j'ai mis en place une surveillance active pour rÃ©agir aux anomalies de marchÃ© sans regarder les Ã©crans :
RÃ¨gle d'alerte 1 : Si Bitcoin Price > 70,000$ â†’ Envoi Email Ã‰quipe Trading.
RÃ¨gle d'alerte 2 : Si Variation > 5% en 1h (VolatilitÃ© extrÃªme) â†’ Notification Critique.

### 3. Gouvernance des DonnÃ©es (Azure Purview)
Pour documenter ce flux de donnÃ©es, j'ai connectÃ© Azure Purview au compte Synapse. Cela permet de :
Scanner automatiquement le schÃ©ma des donnÃ©es.
CrÃ©er un catalogue de donnÃ©es (Data Catalog) pour que les analystes retrouvent facilement les tables CryptoIndicators.

## ðŸ”§ DÃ©fis Techniques & RÃ©solutions (Troubleshooting)
### ðŸ”´ ProblÃ¨me 1 : Latence et "Backpressure"
* SymptÃ´me : Les donnÃ©es arrivaient dans Synapse avec du retard.
* Cause : L'Azure Function envoyait les donnÃ©es une par une, saturant le rÃ©seau.
* Solution : ImplÃ©mentation de l'envoi par Batch (lots) vers Event Hubs pour optimiser le dÃ©bit.

### ðŸ”´ ProblÃ¨me 2 : Quotas API (Rate Limiting)
* DÃ©fi : L'API gratuite de CoinGecko bloque les IP si trop de requÃªtes.
* Solution : Configuration prÃ©cise du Timer Trigger (toutes les 5 min) et gestion des erreurs HTTP 429 (Too Many Requests) avec une logique de "retry" (rÃ©essai).

### ðŸ”´ ProblÃ¨me 3 : CoÃ»ts Azure Synapse
* DÃ©fi : Les Pools SQL dÃ©diÃ©s coÃ»tent cher s'ils tournent 24/7.
* Solution FinOps : Mise en place d'un script d'automatisation pour "Pauser" le pool Synapse pendant les heures creuses (nuit/weekend) lors des phases de test.


## ðŸ“¸ AperÃ§u de la Solution
### Configuration Event Hubs (Ingestion)
Point d'entrÃ©e des donnÃ©es streaming.

![alt text](eventhub-config.png)

### Logique de Traitement (Stream Analytics)
RequÃªte SQL temps rÃ©el directement dans le portail Azure.

![alt text](stream-analytics-query.png)

### Visualisation Power BI
Comparaison temps rÃ©el Bitcoin vs Ethereum et moyennes mobiles.

![alt text](powerbi-crypto.png)

### SystÃ¨me d'Alerte
Configuration des seuils critiques dans Azure Monitor.

![alt text](azure-monitor-alert.png)

## ðŸš€ CompÃ©tences Acquises
* Architecture Serverless : MaÃ®trise des Azure Functions et des triggers Ã©vÃ©nementiels.
* Streaming Data : ComprÃ©hension des concepts de fenÃªtrage temporel avec Stream Analytics.
* Monitoring AvancÃ© : CrÃ©ation d'alertes basÃ©es sur des logs et mÃ©triques.
* IntÃ©gration PaaS : CapacitÃ© Ã  connecter des services hÃ©tÃ©rogÃ¨nes (API -> Event Hub -> Synapse -> Power BI).
